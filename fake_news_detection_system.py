# -*- coding: utf-8 -*-
"""Fake News Detection System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kdc8htEKJ0S2rRZj8w6lNScXbZfPV6d7
"""

import numpy as np
import pandas as pd
import re   #for searching words in text in dataset
import string
from nltk.corpus import stopwords  #the words which doesn't add much value to a paragraph i.e. the articles: a ,the and what,where
from nltk.stem.porter import PorterStemmer  #to give root word
from sklearn.feature_extraction.text import TfidfVectorizer #To convert text into feature vectore like numbers
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

import nltk
nltk.download('stopwords')

print(stopwords.words('english'))

fake_data=pd.read_csv('Fake.csv')
true_data=pd.read_csv('True.csv')

fake_data.head()

true_data.head()

fake_data["class"]=0
true_data["class"]=1

fake_data.shape,true_data.shape

#data taken for testing
fake_data_manual_testing=fake_data.tail(10)
for i in range(23480,23470,-1):
    fake_data.drop([i],axis=0,inplace=True)

true_data_manual_testing=true_data.tail(10)
for j in range(21406,21416,-1):
   true_data.drop([j],axis=0,inplace=True)

"""Merge Dataset"""

data_manual_testing=pd.concat([fake_data_manual_testing,true_data_manual_testing],axis=0)
data_manual_testing.to_csv("manual_testing.csv")

data_merge=pd.concat([fake_data,true_data],axis=0)
data_merge.head(10)

data=data_merge.drop(["title","subject","date"],axis=1)
data.head(10)

#shuffle the dataset
data=data.sample(frac=1)

data.head(10)

x = data["class"].value_counts().index  # Get the unique class values (0 and 1)
height = data["class"].value_counts().values  # Get the counts for each class

plt.bar(x, height, color=["violet", "blue"])
plt.xticks(x, ['Fake', 'Real'])  # Set x-axis labels for better readability
plt.xlabel("News Type")
plt.ylabel("Count")
plt.title("Fake vs. Real News Predictions")
plt.show()

# x=data["class"]
# # y=([''])
# plt.bar(x, data["class"].value_counts(), color=["green", "red"])
# plt.show()

data.isnull().sum()

def word_drop(text):
    text=text.lower()
    text=re.sub('\[.*?\]','',text)
    text=re.sub("\\W"," ",text)
    text=re.sub('https?://\S+|www\.\S+','',text)
    text=re.sub('<,*?>+','',text)
    text=re.sub('[%s]' % re.escape(string.punctuation),'',text)
    text=re.sub('\n','',text)
    text=re.sub('\w*\d\w*','',text)
    return text

data["text"]=data["text"].apply(word_drop)
data.head(10)

x=data["text"]  #dependent
y=data["class"]

#using date for train and test
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)

vectorizarion=TfidfVectorizer()
xv_train=vectorizarion.fit_transform(x_train) # Fit on training data
xv_test=vectorizarion.transform(x_test) # Transform testing data using the fitted vocabulary

"""Logistic Regression

"""

LR=LogisticRegression()
LR.fit(xv_train,y_train)

LR.score(xv_test,y_test)

pred_LR=LR.predict(xv_test)

print(classification_report(y_test,pred_LR))

"""Decision tree"""

DT=DecisionTreeClassifier()
DT.fit(xv_train,y_train)

DT.score(xv_test,y_test)

pred_DT=DT.predict(xv_test)

print(classification_report(y_test,pred_LR))

"""Random Forest Classifier"""

# Random Forest Classifier
RFC=RandomForestClassifier(random_state=0)
RFC.fit(xv_train,y_train)

pred_RFC=RFC.predict(xv_test)

RFC.score(xv_test,y_test)

print(classification_report(y_test,pred_RFC))

#Manual Testing
def output(n):
  if n==0:
    print("It is a fake news")
  elif n==1:
    print("It is a real news")
def manual_testing(news):
  testing_news={"text":[news]}
  new_def_test=pd.DataFrame(testing_news)
  new_def_test["text"]=new_def_test["text"].apply(word_drop)
  new_x_test=new_def_test["text"]
  new_xv_test=vectorizarion.transform(new_x_test)
  pred_LR=LR.predict(new_xv_test)
  pred_DT=DT.predict(new_xv_test)
  pred_RFC=RFC.predict(new_xv_test)

  return print("\n\nLR Prediction: {} \nDT Prediction: {} \nRFC Prediction: ".format(output(pred_LR),output(pred_DT),output(pred_RFC)))

news=str(input())
manual_testing(news)

plt.pie(data["class"].value_counts(),labels=["Fake","Real"],autopct="%1.1f%%")

plt.show()

from sklearn import metrics
confusion_matrix = metrics.confusion_matrix(y_test, pred_LR)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])
cm_display.plot()
plt.show()

confusion_matrix = metrics.confusion_matrix(y_test, pred_DT)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])
cm_display.plot()
plt.show()

confusion_matrix = metrics.confusion_matrix(y_test, pred_RFC)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])
cm_display.plot()
plt.show()

pip install streamlit

import pickle
with open('LogisticRegression.pkl', 'wb') as f:
    pickle.dump(LR, f)
with open('DecisionTree.pkl', 'wb') as f:
    pickle.dump(DT, f)
with open('RFC.pkl', 'wb') as f:
    pickle.dump(RFC, f)
with open('NBC.pkl', 'wb') as f:
    pickle.dump(NBC, f)
with open('SVM.pkl', 'wb') as f:
    pickle.dump(SVM, f)
with open('tfidf_vectorizer.pkl', 'wb') as file:
    pickle.dump(vectorizarion, file)

import matplotlib.pyplot as plt
import numpy as np


models = ["Logistic Regression", "Decision Tree", "Random Forest"]


accuracy_scores = [0.98, 0.99, 0.98]


plt.figure(figsize=(8, 5))
plt.bar(models, accuracy_scores, color=['blue', 'green', 'orange'])

plt.xlabel("Machine Learning Models")
plt.ylabel("Accuracy Score")
plt.title("Comparison of Model Performance")
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)


for i, score in enumerate(accuracy_scores):
    plt.text(i, score + 0.01, f"{score:.2f}", ha='center', fontsize=12)


plt.show()